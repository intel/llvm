name: Compute Benchmarks

on:
  workflow_dispatch:
    inputs:
      str_name:
        description: Formatted adapter name
        type: choice
        required: true
        default: 'level_zero'
        options:
          - level_zero
          - level_zero_v2
      unit:
        description: Test unit (cpu/gpu)
        type: choice
        required: true
        default: 'gpu'
        options:
          - cpu
          - gpu
      pr_no:
        description: PR number (if 0, it'll run on the main)
        type: number
        required: true
      bench_script_params:
        description: Parameters passed to script executing benchmark
        type: string
        required: false
        default: ''
      sycl_config_params:
        description: Extra params for SYCL configuration
        type: string
        required: false
        default: ''
      sycl_repo:
        description: 'Compiler repo'
        type: string
        required: true
        default: 'intel/llvm'
      sycl_commit:
        description: 'Compiler commit'
        type: string
        required: false
        default: ''
      compute_runtime_commit:
        description: 'Compute Runtime commit'
        type: string
        required: false
        default: ''
      upload_report:
        description: 'Upload HTML report'
        type: boolean
        required: false
        default: false

permissions:
  contents: read
  pull-requests: write

jobs:
  manual:
    name: Compute Benchmarks
    uses: ./.github/workflows/benchmarks-reusable.yml
    with:
      str_name: ${{ inputs.str_name }}
      unit: ${{ inputs.unit }}
      pr_no: ${{ inputs.pr_no }}
      bench_script_params: ${{ inputs.bench_script_params }}
      sycl_config_params: ${{ inputs.sycl_config_params }}
      sycl_repo: ${{ inputs.sycl_repo }}
      sycl_commit: ${{ inputs.sycl_commit }}
      compute_runtime_commit: ${{ inputs.compute_runtime_commit }}
      upload_report: ${{ inputs.upload_report }}
