; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
;
; RUN: opt < %s -LowerESIMD -S | FileCheck %s

; This test checks the result of lowering a function that has
; LLVM-IR instructions that work with SPIR-V builtins.
; This is a complete test just to make sure the correct code gets generated.
; In this example, there are many duplicate calls to the same GenX
; intrinsics, which will be optimized by -early-cse pass.

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-n8:16:32:64"
target triple = "spir64-unknown-unknown-sycldevice"

@__spirv_BuiltInGlobalInvocationId = external dso_local local_unnamed_addr addrspace(1) constant <3 x i64>, align 32

define spir_kernel void @"__spirv_GlobalInvocationId_xyz"(i64 addrspace(1)* %_arg_) {
; CHECK-LABEL: @__spirv_GlobalInvocationId_xyz(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[DOTESIMD6:%.*]] = call <3 x i32> @llvm.genx.local.id.v3i32()
; CHECK-NEXT:    [[LOCAL_ID_X:%.*]] = extractelement <3 x i32> [[DOTESIMD6]], i32 0
; CHECK-NEXT:    [[LOCAL_ID_X_CAST_TY:%.*]] = zext i32 [[LOCAL_ID_X]] to i64
; CHECK-NEXT:    [[DOTESIMD7:%.*]] = call <3 x i32> @llvm.genx.local.size.v3i32()
; CHECK-NEXT:    [[WGSIZE_X:%.*]] = extractelement <3 x i32> [[DOTESIMD7]], i32 0
; CHECK-NEXT:    [[WGSIZE_X_CAST_TY:%.*]] = zext i32 [[WGSIZE_X]] to i64
; CHECK-NEXT:    [[GROUP_ID_X:%.*]] = call i32 @llvm.genx.group.id.x()
; CHECK-NEXT:    [[GROUP_ID_X_CAST_TY:%.*]] = zext i32 [[GROUP_ID_X]] to i64
; CHECK-NEXT:    [[MUL8:%.*]] = mul i64 [[WGSIZE_X_CAST_TY]], [[GROUP_ID_X_CAST_TY]]
; CHECK-NEXT:    [[ADD9:%.*]] = add i64 [[LOCAL_ID_X_CAST_TY]], [[MUL8]]
; CHECK-NEXT:    [[PTRIDX_ASCAST_I18_I:%.*]] = addrspacecast i64 addrspace(1)* [[_ARG_:%.*]] to i64 addrspace(4)*
; CHECK-NEXT:    store i64 [[ADD9]], i64 addrspace(4)* [[PTRIDX_ASCAST_I18_I]], align 8
; CHECK-NEXT:    [[DOTESIMD2:%.*]] = call <3 x i32> @llvm.genx.local.id.v3i32()
; CHECK-NEXT:    [[LOCAL_ID_Y:%.*]] = extractelement <3 x i32> [[DOTESIMD2]], i32 1
; CHECK-NEXT:    [[LOCAL_ID_Y_CAST_TY:%.*]] = zext i32 [[LOCAL_ID_Y]] to i64
; CHECK-NEXT:    [[DOTESIMD3:%.*]] = call <3 x i32> @llvm.genx.local.size.v3i32()
; CHECK-NEXT:    [[WGSIZE_Y:%.*]] = extractelement <3 x i32> [[DOTESIMD3]], i32 1
; CHECK-NEXT:    [[WGSIZE_Y_CAST_TY:%.*]] = zext i32 [[WGSIZE_Y]] to i64
; CHECK-NEXT:    [[GROUP_ID_Y:%.*]] = call i32 @llvm.genx.group.id.y()
; CHECK-NEXT:    [[GROUP_ID_Y_CAST_TY:%.*]] = zext i32 [[GROUP_ID_Y]] to i64
; CHECK-NEXT:    [[MUL4:%.*]] = mul i64 [[WGSIZE_Y_CAST_TY]], [[GROUP_ID_Y_CAST_TY]]
; CHECK-NEXT:    [[ADD5:%.*]] = add i64 [[LOCAL_ID_Y_CAST_TY]], [[MUL4]]
; CHECK-NEXT:    [[PTRIDX_I12_I:%.*]] = getelementptr inbounds i64, i64 addrspace(1)* [[_ARG_]], i64 1
; CHECK-NEXT:    [[PTRIDX_ASCAST_I13_I:%.*]] = addrspacecast i64 addrspace(1)* [[PTRIDX_I12_I]] to i64 addrspace(4)*
; CHECK-NEXT:    store i64 [[ADD5]], i64 addrspace(4)* [[PTRIDX_ASCAST_I13_I]], align 8
; CHECK-NEXT:    [[DOTESIMD:%.*]] = call <3 x i32> @llvm.genx.local.id.v3i32()
; CHECK-NEXT:    [[LOCAL_ID_Z:%.*]] = extractelement <3 x i32> [[DOTESIMD]], i32 2
; CHECK-NEXT:    [[LOCAL_ID_Z_CAST_TY:%.*]] = zext i32 [[LOCAL_ID_Z]] to i64
; CHECK-NEXT:    [[DOTESIMD1:%.*]] = call <3 x i32> @llvm.genx.local.size.v3i32()
; CHECK-NEXT:    [[WGSIZE_Z:%.*]] = extractelement <3 x i32> [[DOTESIMD1]], i32 2
; CHECK-NEXT:    [[WGSIZE_Z_CAST_TY:%.*]] = zext i32 [[WGSIZE_Z]] to i64
; CHECK-NEXT:    [[GROUP_ID_Z:%.*]] = call i32 @llvm.genx.group.id.z()
; CHECK-NEXT:    [[GROUP_ID_Z_CAST_TY:%.*]] = zext i32 [[GROUP_ID_Z]] to i64
; CHECK-NEXT:    [[MUL:%.*]] = mul i64 [[WGSIZE_Z_CAST_TY]], [[GROUP_ID_Z_CAST_TY]]
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[LOCAL_ID_Z_CAST_TY]], [[MUL]]
; CHECK-NEXT:    [[PTRIDX_I_I:%.*]] = getelementptr inbounds i64, i64 addrspace(1)* [[_ARG_]], i64 2
; CHECK-NEXT:    [[PTRIDX_ASCAST_I_I:%.*]] = addrspacecast i64 addrspace(1)* [[PTRIDX_I_I]] to i64 addrspace(4)*
; CHECK-NEXT:    store i64 [[ADD]], i64 addrspace(4)* [[PTRIDX_ASCAST_I_I]], align 8
; CHECK-NEXT:    ret void
;
entry:
  %0 = load <3 x i64>, <3 x i64> addrspace(4)* addrspacecast (<3 x i64> addrspace(1)* @__spirv_BuiltInGlobalInvocationId to <3 x i64> addrspace(4)*), align 32
  %1 = extractelement <3 x i64> %0, i64 0
  %ptridx.ascast.i18.i = addrspacecast i64 addrspace(1)* %_arg_ to i64 addrspace(4)*
  store i64 %1, i64 addrspace(4)* %ptridx.ascast.i18.i
  %2 = extractelement <3 x i64> %0, i64 1
  %ptridx.i12.i = getelementptr inbounds i64, i64 addrspace(1)* %_arg_, i64 1
  %ptridx.ascast.i13.i = addrspacecast i64 addrspace(1)* %ptridx.i12.i to i64 addrspace(4)*
  store i64 %2, i64 addrspace(4)* %ptridx.ascast.i13.i
  %3 = extractelement <3 x i64> %0, i64 2
  %ptridx.i.i = getelementptr inbounds i64, i64 addrspace(1)* %_arg_, i64 2
  %ptridx.ascast.i.i = addrspacecast i64 addrspace(1)* %ptridx.i.i to i64 addrspace(4)*
  store i64 %3, i64 addrspace(4)* %ptridx.ascast.i.i
  ret void
}
