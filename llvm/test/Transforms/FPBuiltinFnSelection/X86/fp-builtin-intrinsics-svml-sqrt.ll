; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 4
; RUN: opt -mattr=-sse -alt-math-library=svml -fpbuiltin-fn-selection -S < %s | FileCheck %s -check-prefix=NOSSE
; RUN: opt -mattr=+sse2 -alt-math-library=svml -fpbuiltin-fn-selection -S < %s | FileCheck %s -check-prefix=SSE2
; RUN: opt -mattr=+avx2 -alt-math-library=svml -fpbuiltin-fn-selection -S < %s | FileCheck %s -check-prefix=AVX2
; RUN: opt -mattr=+avx512f -alt-math-library=svml -fpbuiltin-fn-selection -S < %s | FileCheck %s -check-prefix=AVX512F
; RUN: opt -mattr=+avx512fp16 -alt-math-library=svml -fpbuiltin-fn-selection -S < %s | FileCheck %s -check-prefix=AVX512FP16

; Test if fpbuiltin.sqrt for float/double could be transformed to llvm builtins
; when SSE2, AVX2, AVX512F, AVX512FP16 is available.
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define float @svml_sqrt_with_sse(float %f, <4 x float> %v4f, <8 x float> %v8f, <16 x float> %v16f,
; NOSSE-LABEL: define float @svml_sqrt_with_sse(
; NOSSE-SAME: float [[F:%.*]], <4 x float> [[V4F:%.*]], <8 x float> [[V8F:%.*]], <16 x float> [[V16F:%.*]], double [[D:%.*]], <2 x double> [[V2D:%.*]], <4 x double> [[V4D:%.*]], <8 x double> [[V8D:%.*]], half [[H:%.*]], <4 x half> [[V4H:%.*]], <8 x half> [[V8H:%.*]], <16 x half> [[V16H:%.*]], <32 x half> [[V32H:%.*]]) #[[ATTR0:[0-9]+]] {
; NOSSE-NEXT:  entry:
; NOSSE-NEXT:    [[TMP0:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; NOSSE-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; NOSSE-NEXT:    [[TMP2:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; NOSSE-NEXT:    [[TMP3:%.*]] = call <4 x float> @__svml_sqrtf4_ha(<4 x float> [[V4F]])
; NOSSE-NEXT:    [[TMP4:%.*]] = call <4 x float> @__svml_sqrtf4(<4 x float> [[V4F]])
; NOSSE-NEXT:    [[TMP5:%.*]] = call <4 x float> @__svml_sqrtf4_ep(<4 x float> [[V4F]])
; NOSSE-NEXT:    [[TMP6:%.*]] = call <8 x float> @__svml_sqrtf8_ha(<8 x float> [[V8F]])
; NOSSE-NEXT:    [[TMP7:%.*]] = call <8 x float> @__svml_sqrtf8(<8 x float> [[V8F]])
; NOSSE-NEXT:    [[TMP8:%.*]] = call <8 x float> @__svml_sqrtf8_ep(<8 x float> [[V8F]])
; NOSSE-NEXT:    [[TMP9:%.*]] = call <16 x float> @__svml_sqrtf16_ha(<16 x float> [[V16F]])
; NOSSE-NEXT:    [[TMP10:%.*]] = call <16 x float> @__svml_sqrtf16(<16 x float> [[V16F]])
; NOSSE-NEXT:    [[TMP11:%.*]] = call <16 x float> @__svml_sqrtf16_ep(<16 x float> [[V16F]])
; NOSSE-NEXT:    [[TMP12:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; NOSSE-NEXT:    [[TMP13:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; NOSSE-NEXT:    [[TMP14:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; NOSSE-NEXT:    [[TMP15:%.*]] = call <2 x double> @__svml_sqrt2_ha(<2 x double> [[V2D]])
; NOSSE-NEXT:    [[TMP16:%.*]] = call <2 x double> @__svml_sqrt2(<2 x double> [[V2D]])
; NOSSE-NEXT:    [[TMP17:%.*]] = call <2 x double> @__svml_sqrt2_ep(<2 x double> [[V2D]])
; NOSSE-NEXT:    [[TMP18:%.*]] = call <4 x double> @__svml_sqrt4_ha(<4 x double> [[V4D]])
; NOSSE-NEXT:    [[TMP19:%.*]] = call <4 x double> @__svml_sqrt4(<4 x double> [[V4D]])
; NOSSE-NEXT:    [[TMP20:%.*]] = call <4 x double> @__svml_sqrt4_ep(<4 x double> [[V4D]])
; NOSSE-NEXT:    [[TMP21:%.*]] = call <8 x double> @__svml_sqrt8_ha(<8 x double> [[V8D]])
; NOSSE-NEXT:    [[TMP22:%.*]] = call <8 x double> @__svml_sqrt8(<8 x double> [[V8D]])
; NOSSE-NEXT:    [[TMP23:%.*]] = call <8 x double> @__svml_sqrt8_ep(<8 x double> [[V8D]])
; NOSSE-NEXT:    [[TMP24:%.*]] = call half @__svml_sqrts1_ha(half [[H]])
; NOSSE-NEXT:    [[TMP25:%.*]] = call half @__svml_sqrts1(half [[H]])
; NOSSE-NEXT:    [[TMP26:%.*]] = call half @__svml_sqrts1_ep(half [[H]])
; NOSSE-NEXT:    [[TMP27:%.*]] = call <8 x half> @__svml_sqrts8_ha(<8 x half> [[V8H]])
; NOSSE-NEXT:    [[TMP28:%.*]] = call <8 x half> @__svml_sqrts8(<8 x half> [[V8H]])
; NOSSE-NEXT:    [[TMP29:%.*]] = call <8 x half> @__svml_sqrts8_ep(<8 x half> [[V8H]])
; NOSSE-NEXT:    [[TMP30:%.*]] = call <16 x half> @__svml_sqrts16_ha(<16 x half> [[V16H]])
; NOSSE-NEXT:    [[TMP31:%.*]] = call <16 x half> @__svml_sqrts16(<16 x half> [[V16H]])
; NOSSE-NEXT:    [[TMP32:%.*]] = call <16 x half> @__svml_sqrts16_ep(<16 x half> [[V16H]])
; NOSSE-NEXT:    [[TMP33:%.*]] = call <32 x half> @__svml_sqrts32_ha(<32 x half> [[V32H]])
; NOSSE-NEXT:    [[TMP34:%.*]] = call <32 x half> @__svml_sqrts32(<32 x half> [[V32H]])
; NOSSE-NEXT:    [[TMP35:%.*]] = call <32 x half> @__svml_sqrts32_ep(<32 x half> [[V32H]])
; NOSSE-NEXT:    ret float [[TMP0]]
;
; SSE2-LABEL: define float @svml_sqrt_with_sse(
; SSE2-SAME: float [[F:%.*]], <4 x float> [[V4F:%.*]], <8 x float> [[V8F:%.*]], <16 x float> [[V16F:%.*]], double [[D:%.*]], <2 x double> [[V2D:%.*]], <4 x double> [[V4D:%.*]], <8 x double> [[V8D:%.*]], half [[H:%.*]], <4 x half> [[V4H:%.*]], <8 x half> [[V8H:%.*]], <16 x half> [[V16H:%.*]], <32 x half> [[V32H:%.*]]) #[[ATTR0:[0-9]+]] {
; SSE2-NEXT:  entry:
; SSE2-NEXT:    [[TMP0:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; SSE2-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; SSE2-NEXT:    [[TMP2:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; SSE2-NEXT:    [[TMP3:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; SSE2-NEXT:    [[TMP4:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; SSE2-NEXT:    [[TMP5:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; SSE2-NEXT:    [[TMP6:%.*]] = call <8 x float> @__svml_sqrtf8_ha(<8 x float> [[V8F]])
; SSE2-NEXT:    [[TMP7:%.*]] = call <8 x float> @__svml_sqrtf8(<8 x float> [[V8F]])
; SSE2-NEXT:    [[TMP8:%.*]] = call <8 x float> @__svml_sqrtf8_ep(<8 x float> [[V8F]])
; SSE2-NEXT:    [[TMP9:%.*]] = call <16 x float> @__svml_sqrtf16_ha(<16 x float> [[V16F]])
; SSE2-NEXT:    [[TMP10:%.*]] = call <16 x float> @__svml_sqrtf16(<16 x float> [[V16F]])
; SSE2-NEXT:    [[TMP11:%.*]] = call <16 x float> @__svml_sqrtf16_ep(<16 x float> [[V16F]])
; SSE2-NEXT:    [[TMP12:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; SSE2-NEXT:    [[TMP13:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; SSE2-NEXT:    [[TMP14:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; SSE2-NEXT:    [[TMP15:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; SSE2-NEXT:    [[TMP16:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; SSE2-NEXT:    [[TMP17:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; SSE2-NEXT:    [[TMP18:%.*]] = call <4 x double> @__svml_sqrt4_ha(<4 x double> [[V4D]])
; SSE2-NEXT:    [[TMP19:%.*]] = call <4 x double> @__svml_sqrt4(<4 x double> [[V4D]])
; SSE2-NEXT:    [[TMP20:%.*]] = call <4 x double> @__svml_sqrt4_ep(<4 x double> [[V4D]])
; SSE2-NEXT:    [[TMP21:%.*]] = call <8 x double> @__svml_sqrt8_ha(<8 x double> [[V8D]])
; SSE2-NEXT:    [[TMP22:%.*]] = call <8 x double> @__svml_sqrt8(<8 x double> [[V8D]])
; SSE2-NEXT:    [[TMP23:%.*]] = call <8 x double> @__svml_sqrt8_ep(<8 x double> [[V8D]])
; SSE2-NEXT:    [[TMP24:%.*]] = call half @__svml_sqrts1_ha(half [[H]])
; SSE2-NEXT:    [[TMP25:%.*]] = call half @__svml_sqrts1(half [[H]])
; SSE2-NEXT:    [[TMP26:%.*]] = call half @__svml_sqrts1_ep(half [[H]])
; SSE2-NEXT:    [[TMP27:%.*]] = call <8 x half> @__svml_sqrts8_ha(<8 x half> [[V8H]])
; SSE2-NEXT:    [[TMP28:%.*]] = call <8 x half> @__svml_sqrts8(<8 x half> [[V8H]])
; SSE2-NEXT:    [[TMP29:%.*]] = call <8 x half> @__svml_sqrts8_ep(<8 x half> [[V8H]])
; SSE2-NEXT:    [[TMP30:%.*]] = call <16 x half> @__svml_sqrts16_ha(<16 x half> [[V16H]])
; SSE2-NEXT:    [[TMP31:%.*]] = call <16 x half> @__svml_sqrts16(<16 x half> [[V16H]])
; SSE2-NEXT:    [[TMP32:%.*]] = call <16 x half> @__svml_sqrts16_ep(<16 x half> [[V16H]])
; SSE2-NEXT:    [[TMP33:%.*]] = call <32 x half> @__svml_sqrts32_ha(<32 x half> [[V32H]])
; SSE2-NEXT:    [[TMP34:%.*]] = call <32 x half> @__svml_sqrts32(<32 x half> [[V32H]])
; SSE2-NEXT:    [[TMP35:%.*]] = call <32 x half> @__svml_sqrts32_ep(<32 x half> [[V32H]])
; SSE2-NEXT:    ret float [[TMP0]]
;
; AVX2-LABEL: define float @svml_sqrt_with_sse(
; AVX2-SAME: float [[F:%.*]], <4 x float> [[V4F:%.*]], <8 x float> [[V8F:%.*]], <16 x float> [[V16F:%.*]], double [[D:%.*]], <2 x double> [[V2D:%.*]], <4 x double> [[V4D:%.*]], <8 x double> [[V8D:%.*]], half [[H:%.*]], <4 x half> [[V4H:%.*]], <8 x half> [[V8H:%.*]], <16 x half> [[V16H:%.*]], <32 x half> [[V32H:%.*]]) #[[ATTR0:[0-9]+]] {
; AVX2-NEXT:  entry:
; AVX2-NEXT:    [[TMP0:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX2-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX2-NEXT:    [[TMP2:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX2-NEXT:    [[TMP3:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX2-NEXT:    [[TMP4:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX2-NEXT:    [[TMP5:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX2-NEXT:    [[TMP6:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX2-NEXT:    [[TMP7:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX2-NEXT:    [[TMP8:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX2-NEXT:    [[TMP9:%.*]] = call <16 x float> @__svml_sqrtf16_ha(<16 x float> [[V16F]])
; AVX2-NEXT:    [[TMP10:%.*]] = call <16 x float> @__svml_sqrtf16(<16 x float> [[V16F]])
; AVX2-NEXT:    [[TMP11:%.*]] = call <16 x float> @__svml_sqrtf16_ep(<16 x float> [[V16F]])
; AVX2-NEXT:    [[TMP12:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX2-NEXT:    [[TMP13:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX2-NEXT:    [[TMP14:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX2-NEXT:    [[TMP15:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX2-NEXT:    [[TMP16:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX2-NEXT:    [[TMP17:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX2-NEXT:    [[TMP18:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX2-NEXT:    [[TMP19:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX2-NEXT:    [[TMP20:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX2-NEXT:    [[TMP21:%.*]] = call <8 x double> @__svml_sqrt8_ha(<8 x double> [[V8D]])
; AVX2-NEXT:    [[TMP22:%.*]] = call <8 x double> @__svml_sqrt8(<8 x double> [[V8D]])
; AVX2-NEXT:    [[TMP23:%.*]] = call <8 x double> @__svml_sqrt8_ep(<8 x double> [[V8D]])
; AVX2-NEXT:    [[TMP24:%.*]] = call half @__svml_sqrts1_ha(half [[H]])
; AVX2-NEXT:    [[TMP25:%.*]] = call half @__svml_sqrts1(half [[H]])
; AVX2-NEXT:    [[TMP26:%.*]] = call half @__svml_sqrts1_ep(half [[H]])
; AVX2-NEXT:    [[TMP27:%.*]] = call <8 x half> @__svml_sqrts8_ha(<8 x half> [[V8H]])
; AVX2-NEXT:    [[TMP28:%.*]] = call <8 x half> @__svml_sqrts8(<8 x half> [[V8H]])
; AVX2-NEXT:    [[TMP29:%.*]] = call <8 x half> @__svml_sqrts8_ep(<8 x half> [[V8H]])
; AVX2-NEXT:    [[TMP30:%.*]] = call <16 x half> @__svml_sqrts16_ha(<16 x half> [[V16H]])
; AVX2-NEXT:    [[TMP31:%.*]] = call <16 x half> @__svml_sqrts16(<16 x half> [[V16H]])
; AVX2-NEXT:    [[TMP32:%.*]] = call <16 x half> @__svml_sqrts16_ep(<16 x half> [[V16H]])
; AVX2-NEXT:    [[TMP33:%.*]] = call <32 x half> @__svml_sqrts32_ha(<32 x half> [[V32H]])
; AVX2-NEXT:    [[TMP34:%.*]] = call <32 x half> @__svml_sqrts32(<32 x half> [[V32H]])
; AVX2-NEXT:    [[TMP35:%.*]] = call <32 x half> @__svml_sqrts32_ep(<32 x half> [[V32H]])
; AVX2-NEXT:    ret float [[TMP0]]
;
; AVX512F-LABEL: define float @svml_sqrt_with_sse(
; AVX512F-SAME: float [[F:%.*]], <4 x float> [[V4F:%.*]], <8 x float> [[V8F:%.*]], <16 x float> [[V16F:%.*]], double [[D:%.*]], <2 x double> [[V2D:%.*]], <4 x double> [[V4D:%.*]], <8 x double> [[V8D:%.*]], half [[H:%.*]], <4 x half> [[V4H:%.*]], <8 x half> [[V8H:%.*]], <16 x half> [[V16H:%.*]], <32 x half> [[V32H:%.*]]) #[[ATTR0:[0-9]+]] {
; AVX512F-NEXT:  entry:
; AVX512F-NEXT:    [[TMP0:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512F-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512F-NEXT:    [[TMP2:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512F-NEXT:    [[TMP3:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512F-NEXT:    [[TMP4:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512F-NEXT:    [[TMP5:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512F-NEXT:    [[TMP6:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512F-NEXT:    [[TMP7:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512F-NEXT:    [[TMP8:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512F-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512F-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512F-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512F-NEXT:    [[TMP12:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512F-NEXT:    [[TMP13:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512F-NEXT:    [[TMP14:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512F-NEXT:    [[TMP15:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512F-NEXT:    [[TMP16:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512F-NEXT:    [[TMP17:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512F-NEXT:    [[TMP18:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512F-NEXT:    [[TMP19:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512F-NEXT:    [[TMP20:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512F-NEXT:    [[TMP21:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512F-NEXT:    [[TMP22:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512F-NEXT:    [[TMP23:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512F-NEXT:    [[TMP24:%.*]] = call half @__svml_sqrts1_ha(half [[H]])
; AVX512F-NEXT:    [[TMP25:%.*]] = call half @__svml_sqrts1(half [[H]])
; AVX512F-NEXT:    [[TMP26:%.*]] = call half @__svml_sqrts1_ep(half [[H]])
; AVX512F-NEXT:    [[TMP27:%.*]] = call <8 x half> @__svml_sqrts8_ha(<8 x half> [[V8H]])
; AVX512F-NEXT:    [[TMP28:%.*]] = call <8 x half> @__svml_sqrts8(<8 x half> [[V8H]])
; AVX512F-NEXT:    [[TMP29:%.*]] = call <8 x half> @__svml_sqrts8_ep(<8 x half> [[V8H]])
; AVX512F-NEXT:    [[TMP30:%.*]] = call <16 x half> @__svml_sqrts16_ha(<16 x half> [[V16H]])
; AVX512F-NEXT:    [[TMP31:%.*]] = call <16 x half> @__svml_sqrts16(<16 x half> [[V16H]])
; AVX512F-NEXT:    [[TMP32:%.*]] = call <16 x half> @__svml_sqrts16_ep(<16 x half> [[V16H]])
; AVX512F-NEXT:    [[TMP33:%.*]] = call <32 x half> @__svml_sqrts32_ha(<32 x half> [[V32H]])
; AVX512F-NEXT:    [[TMP34:%.*]] = call <32 x half> @__svml_sqrts32(<32 x half> [[V32H]])
; AVX512F-NEXT:    [[TMP35:%.*]] = call <32 x half> @__svml_sqrts32_ep(<32 x half> [[V32H]])
; AVX512F-NEXT:    ret float [[TMP0]]
;
; AVX512FP16-LABEL: define float @svml_sqrt_with_sse(
; AVX512FP16-SAME: float [[F:%.*]], <4 x float> [[V4F:%.*]], <8 x float> [[V8F:%.*]], <16 x float> [[V16F:%.*]], double [[D:%.*]], <2 x double> [[V2D:%.*]], <4 x double> [[V4D:%.*]], <8 x double> [[V8D:%.*]], half [[H:%.*]], <4 x half> [[V4H:%.*]], <8 x half> [[V8H:%.*]], <16 x half> [[V16H:%.*]], <32 x half> [[V32H:%.*]]) #[[ATTR0:[0-9]+]] {
; AVX512FP16-NEXT:  entry:
; AVX512FP16-NEXT:    [[TMP0:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512FP16-NEXT:    [[TMP1:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512FP16-NEXT:    [[TMP2:%.*]] = call float @llvm.sqrt.f32(float [[F]])
; AVX512FP16-NEXT:    [[TMP3:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512FP16-NEXT:    [[TMP4:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512FP16-NEXT:    [[TMP5:%.*]] = call <4 x float> @llvm.sqrt.v4f32(<4 x float> [[V4F]])
; AVX512FP16-NEXT:    [[TMP6:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512FP16-NEXT:    [[TMP7:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512FP16-NEXT:    [[TMP8:%.*]] = call <8 x float> @llvm.sqrt.v8f32(<8 x float> [[V8F]])
; AVX512FP16-NEXT:    [[TMP9:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512FP16-NEXT:    [[TMP10:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512FP16-NEXT:    [[TMP11:%.*]] = call <16 x float> @llvm.sqrt.v16f32(<16 x float> [[V16F]])
; AVX512FP16-NEXT:    [[TMP12:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512FP16-NEXT:    [[TMP13:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512FP16-NEXT:    [[TMP14:%.*]] = call double @llvm.sqrt.f64(double [[D]])
; AVX512FP16-NEXT:    [[TMP15:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512FP16-NEXT:    [[TMP16:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512FP16-NEXT:    [[TMP17:%.*]] = call <2 x double> @llvm.sqrt.v2f64(<2 x double> [[V2D]])
; AVX512FP16-NEXT:    [[TMP18:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512FP16-NEXT:    [[TMP19:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512FP16-NEXT:    [[TMP20:%.*]] = call <4 x double> @llvm.sqrt.v4f64(<4 x double> [[V4D]])
; AVX512FP16-NEXT:    [[TMP21:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512FP16-NEXT:    [[TMP22:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512FP16-NEXT:    [[TMP23:%.*]] = call <8 x double> @llvm.sqrt.v8f64(<8 x double> [[V8D]])
; AVX512FP16-NEXT:    [[TMP24:%.*]] = call half @llvm.sqrt.f16(half [[H]])
; AVX512FP16-NEXT:    [[TMP25:%.*]] = call half @llvm.sqrt.f16(half [[H]])
; AVX512FP16-NEXT:    [[TMP26:%.*]] = call half @llvm.sqrt.f16(half [[H]])
; AVX512FP16-NEXT:    [[TMP27:%.*]] = call <8 x half> @llvm.sqrt.v8f16(<8 x half> [[V8H]])
; AVX512FP16-NEXT:    [[TMP28:%.*]] = call <8 x half> @llvm.sqrt.v8f16(<8 x half> [[V8H]])
; AVX512FP16-NEXT:    [[TMP29:%.*]] = call <8 x half> @llvm.sqrt.v8f16(<8 x half> [[V8H]])
; AVX512FP16-NEXT:    [[TMP30:%.*]] = call <16 x half> @llvm.sqrt.v16f16(<16 x half> [[V16H]])
; AVX512FP16-NEXT:    [[TMP31:%.*]] = call <16 x half> @llvm.sqrt.v16f16(<16 x half> [[V16H]])
; AVX512FP16-NEXT:    [[TMP32:%.*]] = call <16 x half> @llvm.sqrt.v16f16(<16 x half> [[V16H]])
; AVX512FP16-NEXT:    [[TMP33:%.*]] = call <32 x half> @llvm.sqrt.v32f16(<32 x half> [[V32H]])
; AVX512FP16-NEXT:    [[TMP34:%.*]] = call <32 x half> @llvm.sqrt.v32f16(<32 x half> [[V32H]])
; AVX512FP16-NEXT:    [[TMP35:%.*]] = call <32 x half> @llvm.sqrt.v32f16(<32 x half> [[V32H]])
; AVX512FP16-NEXT:    ret float [[TMP0]]
;
  double %d, <2 x double> %v2d, <4 x double> %v4d, <8 x double> %v8d,
  half %h, <4 x half> %v4h, <8 x half> %v8h, <16 x half> %v16h, <32 x half> %v32h) #5 {
entry:
  %t0_0 = call float @llvm.fpbuiltin.sqrt.f32(float %f) #0
  %t0_1 = call float @llvm.fpbuiltin.sqrt.f32(float %f) #1
  %t0_2 = call float @llvm.fpbuiltin.sqrt.f32(float %f) #2
  %t1_0 = call <4 x float> @llvm.fpbuiltin.sqrt.v4f32(<4 x float> %v4f) #0
  %t1_1 = call <4 x float> @llvm.fpbuiltin.sqrt.v4f32(<4 x float> %v4f) #1
  %t1_2 = call <4 x float> @llvm.fpbuiltin.sqrt.v4f32(<4 x float> %v4f) #2
  %t2_0 = call <8 x float> @llvm.fpbuiltin.sqrt.v8f32(<8 x float> %v8f) #0
  %t2_1 = call <8 x float> @llvm.fpbuiltin.sqrt.v8f32(<8 x float> %v8f) #1
  %t2_2 = call <8 x float> @llvm.fpbuiltin.sqrt.v8f32(<8 x float> %v8f) #2
  %t3_0 = call <16 x float> @llvm.fpbuiltin.sqrt.v16f32(<16 x float> %v16f) #0
  %t3_1 = call <16 x float> @llvm.fpbuiltin.sqrt.v16f32(<16 x float> %v16f) #1
  %t3_2 = call <16 x float> @llvm.fpbuiltin.sqrt.v16f32(<16 x float> %v16f) #2
  %t4_0 = call double @llvm.fpbuiltin.sqrt.f64(double %d) #0
  %t4_1 = call double @llvm.fpbuiltin.sqrt.f64(double %d) #1
  %t4_2 = call double @llvm.fpbuiltin.sqrt.f64(double %d) #3
  %t5_0 = call <2 x double> @llvm.fpbuiltin.sqrt.v2f64(<2 x double> %v2d) #0
  %t5_1 = call <2 x double> @llvm.fpbuiltin.sqrt.v2f64(<2 x double> %v2d) #1
  %t5_2 = call <2 x double> @llvm.fpbuiltin.sqrt.v2f64(<2 x double> %v2d) #3
  %t6_0 = call <4 x double> @llvm.fpbuiltin.sqrt.v4f64(<4 x double> %v4d) #0
  %t6_1 = call <4 x double> @llvm.fpbuiltin.sqrt.v4f64(<4 x double> %v4d) #1
  %t6_2 = call <4 x double> @llvm.fpbuiltin.sqrt.v4f64(<4 x double> %v4d) #3
  %t7_0 = call <8 x double> @llvm.fpbuiltin.sqrt.v8f64(<8 x double> %v8d) #0
  %t7_1 = call <8 x double> @llvm.fpbuiltin.sqrt.v8f64(<8 x double> %v8d) #1
  %t7_2 = call <8 x double> @llvm.fpbuiltin.sqrt.v8f64(<8 x double> %v8d) #3
  %t8_0 = call half @llvm.fpbuiltin.sqrt.f16(half %h) #0
  %t8_1 = call half @llvm.fpbuiltin.sqrt.f16(half %h) #1
  %t8_2 = call half @llvm.fpbuiltin.sqrt.f16(half %h) #4
  %t10_0 = call <8 x half> @llvm.fpbuiltin.sqrt.v8f16(<8 x half> %v8h) #0
  %t10_1 = call <8 x half> @llvm.fpbuiltin.sqrt.v8f16(<8 x half> %v8h) #1
  %t10_2 = call <8 x half> @llvm.fpbuiltin.sqrt.v8f16(<8 x half> %v8h) #4
  %t11_0 = call <16 x half> @llvm.fpbuiltin.sqrt.v16f16(<16 x half> %v16h) #0
  %t11_1 = call <16 x half> @llvm.fpbuiltin.sqrt.v16f16(<16 x half> %v16h) #1
  %t11_2 = call <16 x half> @llvm.fpbuiltin.sqrt.v16f16(<16 x half> %v16h) #4
  %t12_0 = call <32 x half> @llvm.fpbuiltin.sqrt.v32f16(<32 x half> %v32h) #0
  %t12_1 = call <32 x half> @llvm.fpbuiltin.sqrt.v32f16(<32 x half> %v32h) #1
  %t12_2 = call <32 x half> @llvm.fpbuiltin.sqrt.v32f16(<32 x half> %v32h) #4
  ret float %t0_0
}

declare float @llvm.fpbuiltin.sqrt.f32(float)
declare <4 x float> @llvm.fpbuiltin.sqrt.v4f32(<4 x float>)
declare <8 x float> @llvm.fpbuiltin.sqrt.v8f32(<8 x float>)
declare <16 x float> @llvm.fpbuiltin.sqrt.v16f32(<16 x float>)
declare double @llvm.fpbuiltin.sqrt.f64(double)
declare <2 x double> @llvm.fpbuiltin.sqrt.v2f64(<2 x double>)
declare <4 x double> @llvm.fpbuiltin.sqrt.v4f64(<4 x double>)
declare <8 x double> @llvm.fpbuiltin.sqrt.v8f64(<8 x double>)
declare half @llvm.fpbuiltin.sqrt.f16(half)
declare <8 x half> @llvm.fpbuiltin.sqrt.v8f16(<8 x half>)
declare <16 x half> @llvm.fpbuiltin.sqrt.v16f16(<16 x half>)
declare <32 x half> @llvm.fpbuiltin.sqrt.v32f16(<32 x half>)

attributes #0 = { "fpbuiltin-max-error"="1.0" }
attributes #1 = { "fpbuiltin-max-error"="4.0" }
attributes #2 = { "fpbuiltin-max-error"="4096.0" }
attributes #3 = { "fpbuiltin-max-error"="67108864.0" }
attributes #4 = { "fpbuiltin-max-error"="32" }
