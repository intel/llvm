// Copyright (C) Codeplay Software Limited

// RUN: clang %s -O3 %stdinclude %polyverify -o %s.exec1 && %s.exec1 &> %s.out1
// RUN: cgeist %s %polyverify %stdinclude -O3 -o %s.execm && %s.execm &> %s.out2
// RUN: rm -f %s.exec1 %s.execm
// RUN: diff %s.out1 %s.out2
// RUN: rm -f %s.out1 %s.out2
// RUN: cgeist %s %polyexec %stdinclude -O3 -o %s.execm && %s.execm > %s.mlir.time; cat %s.mlir.time | FileCheck %s --check-prefix EXEC
// RUN: clang %s -O3 %polyexec %stdinclude -o %s.exec2 && %s.exec2 > %s.clang.time; cat %s.clang.time | FileCheck %s --check-prefix EXEC
// RUN: rm -f %s.exec2 %s.execm %s.mlir.time %s.clang.time

// RUN: clang %s -O3 %stdinclude %polyverify -o %s.exec1 && %s.exec1 &> %s.out1
// RUN: cgeist %s %polyverify %stdinclude -detect-reduction -O3 -o %s.execm && %s.execm &> %s.out2
// RUN: rm -f %s.exec1 %s.execm
// RUN: diff %s.out1 %s.out2
// RUN: rm -f %s.out1 %s.out2

// RUN: cgeist %s %stdinclude -O3 -S | FileCheck %s

/**
 * This version is stamped on May 10, 2016
 *
 * Contact:
 *   Louis-Noel Pouchet <pouchet.ohio-state.edu>
 *   Tomofumi Yuki <tomofumi.yuki.fr>
 *
 * Web address: http://polybench.sourceforge.net
 */
/* nussinov.c: this file is part of PolyBench/C */

#include <stdio.h>
#include <unistd.h>
#include <string.h>
#include <math.h>

/* Include polybench common header. */
#include <polybench.h>

/* Include benchmark-specific header. */
#include "nussinov.h"

/* RNA bases represented as chars, range is [0,3] */
typedef char base;

#define match(b1, b2) (((b1)+(b2)) == 3 ? 1 : 0)
#define max_score(s1, s2) ((s1 >= s2) ? s1 : s2)

/* Array initialization. */
static
void init_array (int n,
                 base POLYBENCH_1D(seq,N,n),
		 DATA_TYPE POLYBENCH_2D(table,N,N,n,n))
{
  int i, j;

  //base is AGCT/0..3
  for (i=0; i <n; i++) {
     seq[i] = (base)((i+1)%4);
  }

  for (i=0; i <n; i++)
     for (j=0; j <n; j++)
       table[i][j] = 0;
}


/* DCE code. Must scan the entire live-out data.
   Can be used also to check the correctness of the output. */
static
void print_array(int n,
		 DATA_TYPE POLYBENCH_2D(table,N,N,n,n))

{
  int i, j;
  int t = 0;

  POLYBENCH_DUMP_START;
  POLYBENCH_DUMP_BEGIN("table");
  for (i = 0; i < n; i++) {
    for (j = i; j < n; j++) {
      if (t % 20 == 0) fprintf (POLYBENCH_DUMP_TARGET, "\n");
      fprintf (POLYBENCH_DUMP_TARGET, DATA_PRINTF_MODIFIER, table[i][j]);
      t++;
    }
  }
  POLYBENCH_DUMP_END("table");
  POLYBENCH_DUMP_FINISH;
}


/* Main computational kernel. The whole function will be timed,
   including the call and return. */
/*
  Original version by Dave Wonnacott at Haverford College <davew@cs.haverford.edu>,
  with help from Allison Lake, Ting Zhou, and Tian Jin,
  based on algorithm by Nussinov, described in Allison Lake's senior thesis.
*/
// static
void kernel_nussinov(int n, base POLYBENCH_1D(seq,N,n),
			   DATA_TYPE POLYBENCH_2D(table,N,N,n,n))
{
  int i, j, k;

#pragma scop
 for (i = _PB_N-1; i >= 0; i--) {
  for (j=i+1; j<_PB_N; j++) {

   if (j-1>=0)
      table[i][j] = max_score(table[i][j], table[i][j-1]);
   if (i+1<_PB_N)
      table[i][j] = max_score(table[i][j], table[i+1][j]);

   if (j-1>=0 && i+1<_PB_N) {
     /* don't allow adjacent elements to bond */
     if (i<j-1)
        table[i][j] = max_score(table[i][j], table[i+1][j-1]+match(seq[i], seq[j]));
     else
        table[i][j] = max_score(table[i][j], table[i+1][j-1]);
   }

   for (k=i+1; k<j; k++) {
      table[i][j] = max_score(table[i][j], table[i][k] + table[k+1][j]);
   }
  }
 }
#pragma endscop

}


int main(int argc, char** argv)
{
  /* Retrieve problem size. */
  int n = N;

  /* Variable declaration/allocation. */
  POLYBENCH_1D_ARRAY_DECL(seq, base, N, n);
  POLYBENCH_2D_ARRAY_DECL(table, DATA_TYPE, N, N, n, n);

  /* Initialize array(s). */
  init_array (n, POLYBENCH_ARRAY(seq), POLYBENCH_ARRAY(table));

  /* Start timer. */
  polybench_start_instruments;

  /* Run kernel. */
  kernel_nussinov (n, POLYBENCH_ARRAY(seq), POLYBENCH_ARRAY(table));

  /* Stop and print timer. */
  polybench_stop_instruments;
  polybench_print_instruments;

  /* Prevent dead-code elimination. All live-out data must be printed
     by the function call in argument. */
  polybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(table)));

  /* Be clean. */
  POLYBENCH_FREE_ARRAY(seq);
  POLYBENCH_FREE_ARRAY(table);

  return 0;
}


// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK: #[[$ATTR_0:.+]] = affine_map<(d0)[s0] -> (-d0 + s0)>
// CHECK: #[[$ATTR_1:.+]] = affine_map<(d0) -> (d0)>
// CHECK: #[[$ATTR_2:.+]] = affine_set<(d0) : (d0 - 1 >= 0)>
// CHECK: #[[$ATTR_3:.+]] = affine_set<(d0, d1) : (d0 - 1 >= 0, d1 - 1 >= 0)>
// CHECK: #[[$ATTR_4:.+]] = affine_set<(d0, d1)[s0] : (d0 + d1 - s0 - 1 >= 0)>
// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL:   llvm.mlir.global internal constant @str7("==END   DUMP_ARRAYS==\0A\00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global internal constant @str6("\0Aend   dump: %[[VAL_0:.*]]\0A\00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global internal constant @str5("%[[VAL_1:.*]] \00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global internal constant @str4("\0A\00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global internal constant @str3("table\00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global internal constant @str2("begin dump: %[[VAL_0]]\00") {addr_space = 0 : i32}
// CHECK:         llvm.func @fprintf(!llvm.ptr, !llvm.ptr, ...) -> i32
// CHECK:         llvm.mlir.global internal constant @str1("==BEGIN DUMP_ARRAYS==\0A\00") {addr_space = 0 : i32}
// CHECK:         llvm.mlir.global external @stderr() {addr_space = 0 : i32} : !llvm.ptr
// CHECK:         llvm.func @malloc(i64) -> !llvm.ptr
// CHECK:         llvm.func @free(!llvm.ptr)
// CHECK:         llvm.func @strcmp(!llvm.ptr, !llvm.ptr) -> i32
// CHECK:         llvm.mlir.global internal constant @str0("\00") {addr_space = 0 : i32}

// CHECK-LABEL:   func.func @main(
// CHECK-SAME:                    %[[VAL_0:.*]]: i32,
// CHECK-SAME:                    %[[VAL_1:.*]]: memref<?xmemref<?xi8>>) -> i32 attributes {llvm.linkage = #llvm.linkage<external>} {
// CHECK:           %[[VAL_2:.*]] = arith.constant 1 : i32
// CHECK:           %[[VAL_3:.*]] = arith.constant 42 : i32
// CHECK:           %[[VAL_4:.*]] = arith.constant 0 : i32
// CHECK:           %[[VAL_5:.*]] = arith.constant 2500 : i64
// CHECK:           %[[VAL_6:.*]] = arith.constant 2500 : i32
// CHECK:           %[[VAL_7:.*]] = call @polybench_alloc_data(%[[VAL_5]], %[[VAL_2]]) : (i64, i32) -> !llvm.ptr
// CHECK:           %[[VAL_8:.*]] = memref.alloc() : memref<2500x2500xi32>
// CHECK:           %[[VAL_9:.*]] = memref.cast %[[VAL_8]] : memref<2500x2500xi32> to memref<?x2500xi32>
// CHECK:           %[[VAL_10:.*]] = "polygeist.pointer2memref"(%[[VAL_7]]) : (!llvm.ptr) -> memref<?xi8>
// CHECK:           call @init_array(%[[VAL_6]], %[[VAL_10]], %[[VAL_9]]) : (i32, memref<?xi8>, memref<?x2500xi32>) -> ()
// CHECK:           call @kernel_nussinov(%[[VAL_6]], %[[VAL_10]], %[[VAL_9]]) : (i32, memref<?xi8>, memref<?x2500xi32>) -> ()
// CHECK:           %[[VAL_11:.*]] = arith.cmpi sgt, %[[VAL_0]], %[[VAL_3]] : i32
// CHECK:           scf.if %[[VAL_11]] {
// CHECK:             %[[VAL_12:.*]] = affine.load %[[VAL_1]][0] : memref<?xmemref<?xi8>>
// CHECK:             %[[VAL_13:.*]] = "polygeist.memref2pointer"(%[[VAL_12]]) : (memref<?xi8>) -> !llvm.ptr
// CHECK:             %[[VAL_14:.*]] = llvm.mlir.addressof @str0 : !llvm.ptr
// CHECK:             %[[VAL_15:.*]] = llvm.getelementptr inbounds %[[VAL_14]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<1 x i8>
// CHECK:             %[[VAL_16:.*]] = llvm.call @strcmp(%[[VAL_13]], %[[VAL_15]]) : (!llvm.ptr, !llvm.ptr) -> i32
// CHECK:             %[[VAL_17:.*]] = arith.cmpi eq, %[[VAL_16]], %[[VAL_4]] : i32
// CHECK:             scf.if %[[VAL_17]] {
// CHECK:               func.call @print_array(%[[VAL_6]], %[[VAL_9]]) : (i32, memref<?x2500xi32>) -> ()
// CHECK:             }
// CHECK:           }
// CHECK:           llvm.call @free(%[[VAL_7]]) : (!llvm.ptr) -> ()
// CHECK:           memref.dealloc %[[VAL_8]] : memref<2500x2500xi32>
// CHECK:           return %[[VAL_4]] : i32
// CHECK:         }

// CHECK-LABEL:   func.func private @polybench_alloc_data(
// CHECK-SAME:                                            %[[VAL_0:.*]]: i64,
// CHECK-SAME:                                            %[[VAL_1:.*]]: i32) -> !llvm.ptr attributes {llvm.linkage = #llvm.linkage<internal>} {
// CHECK:           %[[VAL_2:.*]] = arith.extsi %[[VAL_1]] : i32 to i64
// CHECK:           %[[VAL_3:.*]] = arith.muli %[[VAL_0]], %[[VAL_2]] : i64
// CHECK:           %[[VAL_4:.*]] = llvm.call @malloc(%[[VAL_3]]) : (i64) -> !llvm.ptr
// CHECK:           return %[[VAL_4]] : !llvm.ptr
// CHECK:         }

// CHECK-LABEL:   func.func private @init_array(
// CHECK-SAME:                                  %[[VAL_0:.*]]: i32,
// CHECK-SAME:                                  %[[VAL_1:.*]]: memref<?xi8>,
// CHECK-SAME:                                  %[[VAL_2:.*]]: memref<?x2500xi32>) attributes {llvm.linkage = #llvm.linkage<internal>} {
// CHECK:           %[[VAL_3:.*]] = arith.constant 4 : i32
// CHECK:           %[[VAL_4:.*]] = arith.constant 1 : i32
// CHECK:           %[[VAL_5:.*]] = arith.constant 0 : i32
// CHECK:           %[[VAL_6:.*]] = arith.index_cast %[[VAL_0]] : i32 to index
// CHECK:           affine.for %[[VAL_7:.*]] = 0 to %[[VAL_6]] {
// CHECK:             %[[VAL_8:.*]] = arith.index_cast %[[VAL_7]] : index to i32
// CHECK:             %[[VAL_9:.*]] = arith.addi %[[VAL_8]], %[[VAL_4]] : i32
// CHECK:             %[[VAL_10:.*]] = arith.remsi %[[VAL_9]], %[[VAL_3]] : i32
// CHECK:             %[[VAL_11:.*]] = arith.trunci %[[VAL_10]] : i32 to i8
// CHECK:             affine.store %[[VAL_11]], %[[VAL_1]]{{\[}}%[[VAL_7]]] : memref<?xi8>
// CHECK:           }
// CHECK:           affine.for %[[VAL_12:.*]] = 0 to %[[VAL_6]] {
// CHECK:             affine.for %[[VAL_13:.*]] = 0 to %[[VAL_6]] {
// CHECK:               affine.store %[[VAL_5]], %[[VAL_2]]{{\[}}%[[VAL_12]], %[[VAL_13]]] : memref<?x2500xi32>
// CHECK:             }
// CHECK:           }
// CHECK:           return
// CHECK:         }

// CHECK-LABEL:   func.func @kernel_nussinov(
// CHECK-SAME:                               %[[VAL_0:.*]]: i32,
// CHECK-SAME:                               %[[VAL_1:.*]]: memref<?xi8>,
// CHECK-SAME:                               %[[VAL_2:.*]]: memref<?x2500xi32>) attributes {llvm.linkage = #llvm.linkage<external>} {
// CHECK:           %[[VAL_3:.*]] = arith.constant 3 : i32
// CHECK:           %[[VAL_4:.*]] = arith.index_cast %[[VAL_0]] : i32 to index
// CHECK:           affine.for %[[VAL_5:.*]] = 0 to %[[VAL_4]] {
// CHECK:             affine.for %[[VAL_6:.*]] = #[[$ATTR_0]](%[[VAL_5]]){{\[}}%[[VAL_4]]] to %[[VAL_4]] {
// CHECK:               affine.if #[[$ATTR_2]](%[[VAL_6]]) {
// CHECK:                 %[[VAL_7:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_8:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                 %[[VAL_9:.*]] = arith.cmpi sge, %[[VAL_7]], %[[VAL_8]] : i32
// CHECK:                 %[[VAL_10:.*]] = scf.if %[[VAL_9]] -> (i32) {
// CHECK:                   %[[VAL_11:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   scf.yield %[[VAL_11]] : i32
// CHECK:                 } else {
// CHECK:                   %[[VAL_12:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                   scf.yield %[[VAL_12]] : i32
// CHECK:                 }
// CHECK:                 affine.store %[[VAL_10]], %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:               }
// CHECK:               affine.if #[[$ATTR_2]](%[[VAL_5]]) {
// CHECK:                 %[[VAL_13:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_14:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_15:.*]] = arith.cmpi sge, %[[VAL_13]], %[[VAL_14]] : i32
// CHECK:                 %[[VAL_16:.*]] = scf.if %[[VAL_15]] -> (i32) {
// CHECK:                   %[[VAL_17:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   scf.yield %[[VAL_17]] : i32
// CHECK:                 } else {
// CHECK:                   %[[VAL_18:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   scf.yield %[[VAL_18]] : i32
// CHECK:                 }
// CHECK:                 affine.store %[[VAL_16]], %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:               }
// CHECK:               affine.if #[[$ATTR_3]](%[[VAL_6]], %[[VAL_5]]) {
// CHECK:                 affine.if #[[$ATTR_4]](%[[VAL_5]], %[[VAL_6]]){{\[}}%[[VAL_4]]] {
// CHECK:                   %[[VAL_19:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   %[[VAL_20:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                   %[[VAL_21:.*]] = affine.load %[[VAL_1]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1] : memref<?xi8>
// CHECK:                   %[[VAL_22:.*]] = arith.extsi %[[VAL_21]] : i8 to i32
// CHECK:                   %[[VAL_23:.*]] = affine.load %[[VAL_1]]{{\[}}%[[VAL_6]]] : memref<?xi8>
// CHECK:                   %[[VAL_24:.*]] = arith.extsi %[[VAL_23]] : i8 to i32
// CHECK:                   %[[VAL_25:.*]] = arith.addi %[[VAL_22]], %[[VAL_24]] : i32
// CHECK:                   %[[VAL_26:.*]] = arith.cmpi eq, %[[VAL_25]], %[[VAL_3]] : i32
// CHECK:                   %[[VAL_27:.*]] = arith.extui %[[VAL_26]] : i1 to i32
// CHECK:                   %[[VAL_28:.*]] = arith.addi %[[VAL_20]], %[[VAL_27]] : i32
// CHECK:                   %[[VAL_29:.*]] = arith.cmpi sge, %[[VAL_19]], %[[VAL_28]] : i32
// CHECK:                   %[[VAL_30:.*]] = scf.if %[[VAL_29]] -> (i32) {
// CHECK:                     %[[VAL_31:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                     scf.yield %[[VAL_31]] : i32
// CHECK:                   } else {
// CHECK:                     %[[VAL_32:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                     %[[VAL_33:.*]] = affine.load %[[VAL_1]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1] : memref<?xi8>
// CHECK:                     %[[VAL_34:.*]] = arith.extsi %[[VAL_33]] : i8 to i32
// CHECK:                     %[[VAL_35:.*]] = arith.addi %[[VAL_34]], %[[VAL_24]] : i32
// CHECK:                     %[[VAL_36:.*]] = arith.cmpi eq, %[[VAL_35]], %[[VAL_3]] : i32
// CHECK:                     %[[VAL_37:.*]] = arith.extui %[[VAL_36]] : i1 to i32
// CHECK:                     %[[VAL_38:.*]] = arith.addi %[[VAL_32]], %[[VAL_37]] : i32
// CHECK:                     scf.yield %[[VAL_38]] : i32
// CHECK:                   }
// CHECK:                   affine.store %[[VAL_30]], %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 } else {
// CHECK:                   %[[VAL_39:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   %[[VAL_40:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                   %[[VAL_41:.*]] = arith.cmpi sge, %[[VAL_39]], %[[VAL_40]] : i32
// CHECK:                   %[[VAL_42:.*]] = scf.if %[[VAL_41]] -> (i32) {
// CHECK:                     %[[VAL_43:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                     scf.yield %[[VAL_43]] : i32
// CHECK:                   } else {
// CHECK:                     %[[VAL_44:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]), %[[VAL_6]] - 1] : memref<?x2500xi32>
// CHECK:                     scf.yield %[[VAL_44]] : i32
// CHECK:                   }
// CHECK:                   affine.store %[[VAL_42]], %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 }
// CHECK:               }
// CHECK:               affine.for %[[VAL_45:.*]] = #[[$ATTR_0]](%[[VAL_5]]){{\[}}%[[VAL_4]]] to #[[$ATTR_1]](%[[VAL_6]]) {
// CHECK:                 %[[VAL_46:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_47:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_45]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_48:.*]] = affine.load %[[VAL_2]]{{\[}}%[[VAL_45]] + 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                 %[[VAL_49:.*]] = arith.addi %[[VAL_47]], %[[VAL_48]] : i32
// CHECK:                 %[[VAL_50:.*]] = arith.cmpi sge, %[[VAL_46]], %[[VAL_49]] : i32
// CHECK:                 %[[VAL_51:.*]] = scf.if %[[VAL_50]] -> (i32) {
// CHECK:                   %[[VAL_52:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:                   scf.yield %[[VAL_52]] : i32
// CHECK:                 } else {
// CHECK:                   %[[VAL_53:.*]] = affine.load %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_45]]] : memref<?x2500xi32>
// CHECK:                   %[[VAL_54:.*]] = arith.addi %[[VAL_53]], %[[VAL_48]] : i32
// CHECK:                   scf.yield %[[VAL_54]] : i32
// CHECK:                 }
// CHECK:                 affine.store %[[VAL_51]], %[[VAL_2]][-%[[VAL_5]] + symbol(%[[VAL_4]]) - 1, %[[VAL_6]]] : memref<?x2500xi32>
// CHECK:               }
// CHECK:             }
// CHECK:           }
// CHECK:           return
// CHECK:         }

// CHECK-LABEL:   func.func private @print_array(
// CHECK-SAME:                                   %[[VAL_0:.*]]: i32,
// CHECK-SAME:                                   %[[VAL_1:.*]]: memref<?x2500xi32>) attributes {llvm.linkage = #llvm.linkage<internal>} {
// CHECK:           %[[VAL_2:.*]] = arith.constant 20 : i32
// CHECK:           %[[VAL_3:.*]] = arith.constant 0 : i32
// CHECK:           %[[VAL_4:.*]] = llvm.mlir.addressof @stderr : !llvm.ptr
// CHECK:           %[[VAL_5:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:           %[[VAL_6:.*]] = llvm.mlir.addressof @str1 : !llvm.ptr
// CHECK:           %[[VAL_7:.*]] = llvm.getelementptr inbounds %[[VAL_6]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<23 x i8>
// CHECK:           %[[VAL_8:.*]] = llvm.call @fprintf(%[[VAL_5]], %[[VAL_7]]) : (!llvm.ptr, !llvm.ptr) -> i32
// CHECK:           %[[VAL_9:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:           %[[VAL_10:.*]] = llvm.mlir.addressof @str2 : !llvm.ptr
// CHECK:           %[[VAL_11:.*]] = llvm.getelementptr inbounds %[[VAL_10]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<15 x i8>
// CHECK:           %[[VAL_12:.*]] = llvm.mlir.addressof @str3 : !llvm.ptr
// CHECK:           %[[VAL_13:.*]] = llvm.getelementptr inbounds %[[VAL_12]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<6 x i8>
// CHECK:           %[[VAL_14:.*]] = llvm.call @fprintf(%[[VAL_9]], %[[VAL_11]], %[[VAL_13]]) : (!llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
// CHECK:           %[[VAL_15:.*]] = llvm.mlir.addressof @str5 : !llvm.ptr
// CHECK:           %[[VAL_16:.*]] = llvm.getelementptr inbounds %[[VAL_15]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<4 x i8>
// CHECK:           %[[VAL_17:.*]] = arith.index_cast %[[VAL_0]] : i32 to index
// CHECK:           %[[VAL_18:.*]] = affine.for %[[VAL_19:.*]] = 0 to %[[VAL_17]] iter_args(%[[VAL_20:.*]] = %[[VAL_3]]) -> (i32) {
// CHECK:             %[[VAL_21:.*]] = arith.subi %[[VAL_17]], %[[VAL_19]] : index
// CHECK:             %[[VAL_22:.*]] = arith.index_cast %[[VAL_20]] : i32 to index
// CHECK:             %[[VAL_23:.*]] = arith.addi %[[VAL_22]], %[[VAL_21]] : index
// CHECK:             %[[VAL_24:.*]] = arith.index_cast %[[VAL_23]] : index to i32
// CHECK:             affine.for %[[VAL_25:.*]] = #[[$ATTR_1]](%[[VAL_19]]) to %[[VAL_17]] {
// CHECK:               %[[VAL_26:.*]] = arith.subi %[[VAL_25]], %[[VAL_19]] : index
// CHECK:               %[[VAL_27:.*]] = arith.addi %[[VAL_22]], %[[VAL_26]] : index
// CHECK:               %[[VAL_28:.*]] = arith.index_cast %[[VAL_27]] : index to i32
// CHECK:               %[[VAL_29:.*]] = arith.remsi %[[VAL_28]], %[[VAL_2]] : i32
// CHECK:               %[[VAL_30:.*]] = arith.cmpi eq, %[[VAL_29]], %[[VAL_3]] : i32
// CHECK:               scf.if %[[VAL_30]] {
// CHECK:                 %[[VAL_31:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:                 %[[VAL_32:.*]] = llvm.mlir.addressof @str4 : !llvm.ptr
// CHECK:                 %[[VAL_33:.*]] = llvm.getelementptr inbounds %[[VAL_32]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<2 x i8>
// CHECK:                 %[[VAL_34:.*]] = llvm.call @fprintf(%[[VAL_31]], %[[VAL_33]]) : (!llvm.ptr, !llvm.ptr) -> i32
// CHECK:               }
// CHECK:               %[[VAL_35:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:               %[[VAL_36:.*]] = affine.load %[[VAL_1]]{{\[}}%[[VAL_19]], %[[VAL_25]]] : memref<?x2500xi32>
// CHECK:               %[[VAL_37:.*]] = llvm.call @fprintf(%[[VAL_35]], %[[VAL_16]], %[[VAL_36]]) : (!llvm.ptr, !llvm.ptr, i32) -> i32
// CHECK:             }
// CHECK:             affine.yield %[[VAL_24]] : i32
// CHECK:           }
// CHECK:           %[[VAL_38:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:           %[[VAL_39:.*]] = llvm.mlir.addressof @str6 : !llvm.ptr
// CHECK:           %[[VAL_40:.*]] = llvm.getelementptr inbounds %[[VAL_39]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<17 x i8>
// CHECK:           %[[VAL_41:.*]] = llvm.call @fprintf(%[[VAL_38]], %[[VAL_40]], %[[VAL_13]]) : (!llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
// CHECK:           %[[VAL_42:.*]] = llvm.load %[[VAL_4]] : !llvm.ptr -> !llvm.ptr
// CHECK:           %[[VAL_43:.*]] = llvm.mlir.addressof @str7 : !llvm.ptr
// CHECK:           %[[VAL_44:.*]] = llvm.getelementptr inbounds %[[VAL_43]][0, 0] : (!llvm.ptr) -> !llvm.ptr, !llvm.array<23 x i8>
// CHECK:           %[[VAL_45:.*]] = llvm.call @fprintf(%[[VAL_42]], %[[VAL_44]]) : (!llvm.ptr, !llvm.ptr) -> i32
// CHECK:           return
// CHECK:         }

// EXEC: {{[0-9]\.[0-9]+}}
