name: SYCL E2E

on:
  workflow_call:
    inputs:
      name:
        type: string
        required: True

      runner:
        type: string
        required: True
      image:
        type: string
        required: False
      image_options:
        type: string
        required: True

      target_devices:
        type: string
        required: False
      extra_cmake_args:
        type: string
        required: False
      tests_selector:
        description: |
          Three possible options: "e2e", "cts", and "benchmarks".
        type: string
        default: "e2e"

      extra_lit_opts:
        description: |
          Extra options to be added to LIT_OPTS.
        type: string
        default: ''

      repo_ref:
        type: string
        required: False
        description: |
          Commit SHA or branch to checkout the intel/llvm repo.
      tests_ref:
        type: string
        required: False
        description: Commit SHA or branch to checkout e2e/cts tests.

      toolchain_artifact:
        type: string
        default: ''
        required: False
      toolchain_artifact_filename:
        type: string
        default: ''
        required: False
      toolchain_decompress_command:
        type: string
        default: ''
        required: False

      e2e_binaries_artifact:
        description: |
          When set in modes other than `run-only` results in artifact upload.
          For `run-only` mode, if specified, means downloading pre-built
          binaries from the artifact. If set to special value `in-container`
          then the binaries are expected to be stored in the container image
          instead of coming from an artifact.
        type: string
        default: ''
        required: False
      e2e_testing_mode:
        description: |
          Testing mode to run E2E tests in, can be either `full`, `build-only`
          or `run-only`.
        type: string
        default: 'full'
      retention-days:
        description: 'E2E/SYCL-CTS binaries artifact retention period.'
        type: string
        default: 1

      install_igc_driver:
        type: string
        required: False
      install_dev_igc_driver:
        type: string
        required: False
      env:
        type: string
        default: '{}'
        required: False

      skip_run:
        type: string
        default: 'false'
        required: False

      cts_testing_mode:
        description: |
          Testing mode to run SYCL-CTS in, can be either `full`, `build-only`
          or `run-only`. In `build-only` mode an artifact of the CTS binaries
          will be uploaded.
        type: string
        default: 'full'

      sycl_cts_artifact:
        type: string
        default: ''
        required: False

      benchmark_upload_results:
        description: |
          Set to true to upload results to git repository storing benchmarking
          results.
        type: string
        default: 'false'
        required: False
      benchmark_save_name:
        description: |
          Save name to use for benchmark results: Save names are stored in
          metadata of result file, and are used to identify benchmark results in
          the same series (e.g. same configuration, same device, etc.).

          Note: Currently, benchmark result filenames are in the format of
          <benchmark_save_name>_<Device>_<Backend>_YYYYMMDD_HHMMSS.json
        type: string
        default: ''
        required: False
      benchmark_preset:
        description: |
          Name of benchmark preset to run.

          See /devops/scripts/benchmarks/presets.py for all presets available.
        type: string
        default: 'Minimal'
        required: False
      # dry-run is passed only to compare.py (to not fail on regression), not to main.py (where such flag would omit all benchmark runs)
      benchmark_dry_run:
        description: |
          Whether or not to fail the workflow upon a regression.
        type: string
        default: 'false'
        required: False
      benchmark_exit_on_failure:
        description: |
          Whether or not to fail the workflow upon a failure.
        type: string
        default: 'false'
        required: False

  workflow_dispatch:
    inputs:
      runner:
        type: choice
        options:
          - '["Linux", "gen12"]'
          - '["amdgpu"]'
          - '["Linux", "arc"]'
          - '["Linux", "pvc"]'
          - '["cts-cpu"]'
          - '["Linux", "build"]'
          - '["cuda"]'
          - '["PVC_PERF"]'
      image:
        type: choice
        options:
          - 'ghcr.io/intel/llvm/sycl_ubuntu2404_nightly:latest'
          - 'ghcr.io/intel/llvm/sycl_prebuilt_tests:sycl-rel-6_2'
          - 'ghcr.io/intel/llvm/sycl_prebuilt_tests:sycl-rel-6_3'
          - 'ghcr.io/intel/llvm/ubuntu2404_intel_drivers:alldeps'
      image_options:
        description: |
          Use option with "--device=/dev/kfd" for AMDGPU, without it for the rest.
        type: choice
        options:
          - '-u 1001 --device=/dev/dri --device=/dev/kfd --privileged --cap-add SYS_ADMIN'
          - '-u 1001 --device=/dev/dri --privileged --cap-add SYS_ADMIN'
          - '-u 1001 --gpus all --cap-add SYS_ADMIN'
      target_devices:
        type: choice
        options:
          - 'level_zero:gpu'
          - 'opencl:cpu'
          - 'opencl:gpu'
          - 'hip:gpu'
          - 'cuda:gpu'
      tests_selector:
        type: choice
        options:
          - e2e
          - cts
          - benchmarks
      toolchain_release_tag:
        description: |
          Tag of a "Nightly" release at https://github.com/intel/llvm/releases.
        default: ''

      env:
        description: |
          Suggested variables: for E2E tests - LIT_FILTER, LIT_FILTER_OUT.
          LIT_OPTS won't work as we redefine it as part of this workflow.

          For SYCL CTS - CTS_TESTS_TO_BUILD to specify which categories to
          build, e.g. {"CTS_TESTS_TO_BUILD":"test_category1 test_category2..."}.

          Format: '{"VAR1":"VAL1","VAR2":"VAL2",...}'
        default: '{}'

      extra_lit_opts:
        description: |
          Extra options to be added to LIT_OPTS.
        default: ''

      e2e_testing_mode:
        type: choice
        options:
          - "full"
          - "build-only"
          - "run-only"

      benchmark_exit_on_failure:
        type: choice
        options:
          - "true"
          - "false"

permissions:
  contents: read
  packages: read

jobs:
  run:
    if: github.event_name == 'workflow_dispatch' || inputs.skip_run == 'false'
    name: ${{ inputs.name }}
    runs-on: ${{ fromJSON(inputs.runner) }}
    permissions:
      contents: write
      packages: read
    container:
      image: ${{ inputs.image || 'ghcr.io/intel/llvm/ubuntu2404_intel_drivers:alldeps'}}
      options: ${{ inputs.image_options }}
    env: ${{ fromJSON(inputs.env) }}
    steps:
    - uses: actions/checkout@v5
      with:
        sparse-checkout: |
          devops
          sycl/cts_exclude_filter
    - name: Register cleanup after job is finished
      uses: ./devops/actions/cleanup
    - name: Reset Intel GPU
      uses: ./devops/actions/reset_gpu
    - name: Install drivers
      if: inputs.e2e_binaries_artifact != 'in-container' && (inputs.install_igc_driver == 'true' || inputs.install_dev_igc_driver == 'true')
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        if [ "${{ inputs.install_dev_igc_driver }}" = "true" ]; then
            # If libllvm14 is already installed (dev igc docker), still return true.
            sudo apt-get install -yqq libllvm14 || true;
        fi
        sudo -E bash devops/scripts/install_drivers.sh devops/dependencies.json ${{ inputs.install_dev_igc_driver == 'true' && 'devops/dependencies-igc-dev.json --use-dev-igc' || '' }} --all
    - name: Source OneAPI TBB vars.sh
      shell: bash
      run: |
        # https://github.com/actions/runner/issues/1964 prevents us from using
        # the ENTRYPOINT in the image.
        env | sort > env_before
        if [ -e /runtimes/oneapi-tbb/env/vars.sh ]; then
          source /runtimes/oneapi-tbb/env/vars.sh;
        elif [ -e /opt/runtimes/oneapi-tbb/env/vars.sh ]; then
          source /opt/runtimes/oneapi-tbb/env/vars.sh;
        else
          echo "no TBB vars in /opt/runtimes or /runtimes";
        fi
        env | sort > env_after
        comm -13 env_before env_after >> $GITHUB_ENV
        rm env_before env_after
    - name: Download SYCL toolchain
      if: inputs.toolchain_artifact != '' && github.event_name != 'workflow_run'
      uses: actions/download-artifact@v5
      with:
        name: ${{ inputs.toolchain_artifact }}
    - name: Download SYCL toolchain [workflow_run]
      # NOTE: This is for `sycl-linux-precommit-aws.yml`.
      if: inputs.toolchain_artifact != '' && github.event_name == 'workflow_run'
      uses: actions/github-script@v8
      with:
        script: |
          const name = '${{ inputs.toolchain_artifact }}'
          let allArtifacts = await github.rest.actions.listWorkflowRunArtifacts({
             owner: context.repo.owner,
             repo: context.repo.repo,
             run_id: context.payload.workflow_run.id,
          });
          let matchArtifact = allArtifacts.data.artifacts.filter((artifact) => {
            return artifact.name == name
          })[0];
          let download = await github.rest.actions.downloadArtifact({
             owner: context.repo.owner,
             repo: context.repo.repo,
             artifact_id: matchArtifact.id,
             archive_format: 'zip',
          });
          let fs = require('fs');
          fs.writeFileSync(`${process.env.GITHUB_WORKSPACE}/` + name + '.zip', Buffer.from(download.data));
    - name: Unzip artifact [workflow_run]
      if: inputs.toolchain_artifact != '' && github.event_name == 'workflow_run'
      run: |
        pwd
        ls
        unzip ${{ inputs.toolchain_artifact }}.zip
        rm ${{ inputs.toolchain_artifact }}.zip
    - name: Extract/Setup SYCL toolchain
      if: inputs.toolchain_artifact != ''
      run: |
        mkdir toolchain
        tar -I '${{ inputs.toolchain_decompress_command }}' -xf ${{ inputs.toolchain_artifact_filename }} -C toolchain
        rm -f ${{ inputs.toolchain_artifact_filename }}
        echo PATH=$PWD/toolchain/bin/:$PATH >> $GITHUB_ENV
        echo LD_LIBRARY_PATH=$PWD/toolchain/lib/:$LD_LIBRARY_PATH >> $GITHUB_ENV
    - name: Download SYCL toolchain using release tag
      if: inputs.toolchain_release_tag != ''
      env:
        TAG: ${{ inputs.toolchain_release_tag }}
      shell: bash
      run: |
        mkdir toolchain
        wget "https://github.com/intel/llvm/releases/download/$TAG/sycl_linux.tar.gz"
        tar xf sycl_linux.tar.gz -C toolchain
        echo PATH=$PWD/toolchain/bin/:$PATH >> $GITHUB_ENV
        echo LD_LIBRARY_PATH=$PWD/toolchain/lib/:$LD_LIBRARY_PATH >> $GITHUB_ENV
    - run: which clang++ sycl-ls
    - run: sycl-ls --verbose
    - run: SYCL_UR_TRACE=1 sycl-ls
    - run: |
          if [ -f /usr/local/lib/igc/IGCTAG.txt ]; then
            cat /usr/local/lib/igc/IGCTAG.txt
          fi

    - name: Run E2E Tests
      if: inputs.tests_selector == 'e2e'
      uses: ./devops/actions/run-tests/e2e
      timeout-minutes: 60
      with:
        ref: ${{ inputs.tests_ref || inputs.repo_ref || github.sha }}
        binaries_artifact: ${{ inputs.e2e_binaries_artifact }}
        testing_mode: ${{ inputs.e2e_testing_mode }}
        extra_cmake_args: ${{ inputs.extra_cmake_args }}
        target_devices: ${{ inputs.target_devices }}
        extra_lit_opts: ${{ inputs.extra_lit_opts }}
        retention-days: ${{ inputs.retention-days }}

    - name: Run SYCL CTS Tests
      if: inputs.tests_selector == 'cts'
      uses: ./devops/actions/run-tests/cts
      # Normally this job takes less than 10m. But sometimes it hangs up and
      # reaches the 360m limit. Set a lower limit to free up the runner earlier.
      timeout-minutes: 35
      with:
        ref: ${{ inputs.tests_ref || 'main' }}
        extra_cmake_args: ${{ inputs.extra_cmake_args }}
        cts_testing_mode: ${{ inputs.cts_testing_mode }}
        sycl_cts_artifact: ${{ inputs.sycl_cts_artifact }}
        target_devices: ${{ inputs.target_devices }}
        retention-days: ${{ inputs.retention-days }}

    - name: Run benchmarks
      if: inputs.tests_selector == 'benchmarks'
      uses: ./devops/actions/run-tests/benchmark
      with:
        target_devices: ${{ inputs.target_devices }}
        upload_results: ${{ inputs.benchmark_upload_results }}
        save_name: ${{ inputs.benchmark_save_name }}
        preset: ${{ inputs.benchmark_preset }}
        dry_run: ${{ inputs.benchmark_dry_run }}
        exit_on_failure: ${{ inputs.benchmark_exit_on_failure }}
        build_ref: ${{ inputs.repo_ref }}
      env:
        RUNNER_TAG: ${{ inputs.runner }}
