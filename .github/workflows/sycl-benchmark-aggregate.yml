name: Aggregate benchmark averages

on:
  schedule:
  - cron: 0 1 * * *
  workflow_dispatch:
    inputs:
      cutoff_timestamp:
        description: "Timestamp "
        type: string
        required: false
  workflow_call:
    inputs:
      cutoff_timestamp:
        type: string
        required: false

permissions:
  contents: read

jobs:
  aggregate:
    name: Aggregate average value for all metrics (median)
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        path: llvm
        sparse-checkout: |
          devops/scripts/benchmarking
    - name: Load benchmarking configuration
      run: |
        # TODO isolate sanitation from benchmark.sh different script
        # use sanitation here
        . llvm/devops/scripts/benchmarking/benchmark-ci.conf;
        echo "PERF_RES_GIT_REPO=$PERF_RES_GIT_REPO" >> $GITHUB_ENV
        echo "PERF_RES_BRANCH=$PERF_RES_BRANCH" >> $GITHUB_ENV
        echo "PERF_RES_PATH=$PERF_RES_PATH" >> $GITHUB_ENV

        if [ -z '${{ inputs.cutoff_timestamp }}' ]; then
          # No time given, use default time period
          echo "CUTOFF_TIMESTAMP=$(date --date="$AVERAGE_CUTOFF_RANGE" +"$TIMESTAMP_FORMAT")" >> $GITHUB_ENV
        else
          # If the provided time is a unix `date` timestamp, convert the time to our format
          _converted_timestamp="$(date --date '${{ inputs.cutoff_timestamp }}' +"$TIMESTAMP_FORMAT" 2> /dev/null)"
          if [ -n "$_converted_timestamp" ]; then
            echo "CUTOFF_TIMESTAMP=$_converted_timestamp" >> $GITHUB_ENV
          else
            # If not a valid unix `date` timestamp, it could be in our timestamp format already.
            # aggregate.py will ensure the timestamp is in the proper format, so we can pass the
            # time forward regardless: 
            echo 'CUTOFF_TIMESTAMP=${{ inputs.cutoff_timestamp }}' >> $GITHUB_ENV
          fi
        fi
    - name: Checkout performance results repository
      run: |
        git clone -b $PERF_RES_BRANCH $PERF_RES_GIT_REPO $PERF_RES_PATH
    - name: Run aggregator on cloned data
      run: |
        for dir in $(find "$PERF_RES_PATH" -mindepth 2 -maxdepth 2 -type d ! -path '*.git*'); do
          _runner="$(basename $(dirname $dir))"
          _testcase="$(basename $dir)"
          python llvm/devops/scripts/benchmarking/aggregate.py "$_runner" "$_testcase" "$CUTOFF_TIMESTAMP"
        done
    - name: Upload average to the repo
      env:
        SSH_KEY: ${{secrets.ACTIONS_DEPLOY_KEY}}
      run: |
        # TODO -- waiting on security clearance
        mkdir -p ~/.ssh
        echo "$SSH_KEY" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        eval "$(ssh-agent -s)"
        ssh-add -k ~/.ssh/id_rsa
        cd $PERF_RES_PATH
        git config --global user.name "iclsrc"
        git config --global user.email "ia.compiler.tools.git@intel.com"
        git add .
        git commit -m "Average aggregate $(date "+%m/%d/%y %H:%M")" -s
        git push
